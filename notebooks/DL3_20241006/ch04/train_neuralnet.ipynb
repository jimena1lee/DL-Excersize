{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720081926684
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/DL-Excersize/notebooks/DL3_20241006/ch04\n",
            "/workspaces/DL-Excersize/notebooks/DL3_20241006\n",
            "0.08656666666666667 0.0882\n",
            "0.90605 0.9086\n",
            "0.9256666666666666 0.9264\n",
            "0.9373833333333333 0.9371\n",
            "0.94435 0.9442\n",
            "0.9522166666666667 0.9491\n",
            "0.9581666666666667 0.9544\n",
            "0.9609166666666666 0.9581\n",
            "0.9649666666666666 0.9592\n",
            "0.9671 0.9625\n",
            "0.97005 0.9655\n",
            "0.9690166666666666 0.9646\n",
            "0.9740333333333333 0.9667\n",
            "0.9756666666666667 0.9689\n",
            "0.9777 0.9702\n",
            "0.9786166666666667 0.9707\n",
            "0.9763833333333334 0.9683\n"
          ]
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "import os, sys\n",
        "print(os.getcwd())\n",
        "\n",
        "current_dir = os.path.dirname(os.getcwd())\n",
        "print(current_dir)\n",
        "os.chdir(current_dir)\n",
        "\n",
        "# sys.path.append(parent_dir)\n",
        "\n",
        "# import torch\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from ch04.two_layer_net import TwoLayerNet\n",
        "\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # 기울기 계산\n",
        "    # grad = network.numerical_gradient(x_batch, t_batch)  # 수치 미분 방식\n",
        "    grad = network.gradient(x_batch, t_batch)  # 오차역전파 방식 (훨씬 빠르다)\n",
        "\n",
        "    # 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
